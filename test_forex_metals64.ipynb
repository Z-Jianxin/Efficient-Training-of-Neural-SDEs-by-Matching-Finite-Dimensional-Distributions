{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f11875",
   "metadata": {},
   "source": [
    "# Validating generator performance notebook (unconditional case).\n",
    "\n",
    "In this notebook, we validate the performance of a given generator model $G_\\theta$ against a specified path bank. In this way we are seeking to evaluate the performance of the generated measure $\\mathbb{P}_{X^\\theta}$ against the real data measure $\\mathbb{P}_{X^{\\text{real}}}$. \n",
    "\n",
    "Naturally choosing a (differentiable) distance on the space these two objects reside on is one of the crucial decisions in GAN training, i.e. MMD, Wasserstein metric, KL, and so on. Here we choose a few metrics that are not the same as those used to train any of the models. We study the following - \n",
    "\n",
    "1) Qualitative plot of marginals of  $\\mathbb{P}_{X^\\theta}$ against $\\mathbb{P}_{X^{\\text{real}}}$, for level values, returns, and squared returns,\n",
    "\n",
    "2) Kolmogorov-Smirnov score and associated p-value for specified marginals between $\\mathbb{P}_{X^\\theta}$ and $\\mathbb{P}_{X^{\\text{real}}}$, \n",
    "\n",
    "3) Autocorrelation (ACF) plot of levels and returns for real and generated paths, \n",
    "\n",
    "4) Cross-covariance matrices for level, returns and squared returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd04683",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim.swa_utils as swa_utils\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "from src.rBergomi import rBergomi\n",
    "from src.gan import sde\n",
    "from src.gan.generators import Generator\n",
    "from src.gan.base import preprocess_real_data, get_real_data, get_synthetic_data\n",
    "from src.utils.helper_functions.data_helper_functions import subtract_initial_point\n",
    "from src.utils.helper_functions.global_helper_functions import get_project_root\n",
    "from src.utils.helper_functions.plot_helper_functions import make_grid\n",
    "from src.evaluation_functions import get_ccor_matrix, generate_ks_results\n",
    "\n",
    "plt.style.use('science')\n",
    "plt.rcParams['axes.titlesize']  = 24\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['axes.labelsize']  = 22\n",
    "plt.rcParams['text.usetex']         = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath, amsfonts}'\n",
    "\n",
    "GOLDEN_RATIO = (1 + np.sqrt(5))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = 'cuda:0'\n",
    "\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if not is_cuda:\n",
    "    print(\"Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\")\n",
    "    \n",
    "# You realistially need GPU access (either natively or via cloud computing) to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdd06d",
   "metadata": {},
   "source": [
    "## 0. Load generator and required data\n",
    "\n",
    "We first load the generator and data we wish to test against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e29c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from src.exp_helpers import get_data\n",
    "data_type = \"forex_metals\"\n",
    "eval_batch_size = 128\n",
    "data_config = {\n",
    "        \"output_dim\": 1,\n",
    "        \"batch_size\": 128,\n",
    "        \"path_length\": 64, # 64\n",
    "        \"dataset_size\": 128 * 256,\n",
    "        \"normalisation\": \"mean_var\",\n",
    "        \"scale\": 1e0,\n",
    "        #\"data_type\": \"forex\",\n",
    "        \"forex_pairs\": [\"XAGUSD\", \"XAUUSD\"],\n",
    "        \"stride_length\": 1,\n",
    "        \"frequency\": \"M1\", # \"H1\"\n",
    "        \"filter_extremal_paths\": False,\n",
    "        \"filter_extremal_pct\": 0.95,\n",
    "        \"end_time\": 2,  # 2\n",
    "        \"tt_split\": 0.8,\n",
    "        \"gbm_params\": [0., 0.2],\n",
    "        \"rB_params\": [0.2**2, 1.5, -0.7, 0.2],\n",
    "        #\"cond_\": \"forex\" == \"rBergomi\",\n",
    "        \"sde_parameters\": [0.2**2, 1.5, -0.7, 0.2],\n",
    "        \"gen_sde_dt_scale\": 1e-1,\n",
    "        \"gen_sde_integration_type\": \"ito\",\n",
    "        \"gen_sde_method\": \"srk\",\n",
    "        \"learning_type\": \"paths\",\n",
    "        \"time_add_type\": \"basic\",\n",
    "        \"filter_by_time\": True,\n",
    "        \"initial_point\": \"scale\",\n",
    "        \"do_transforms\": True,\n",
    "        \"transformations\": OrderedDict([\n",
    "            (\"visibility\", False),\n",
    "            (\"time_difference\", False),\n",
    "            (\"time_normalisation\", False),\n",
    "            (\"lead_lag\", False),\n",
    "            (\"basepoint\", False)\n",
    "        ]),\n",
    "        \"transformation_args\": OrderedDict([\n",
    "            (\"visibility\", {}),\n",
    "            (\"time_difference\", {}),\n",
    "            (\"time_normalisation\", {}),\n",
    "            (\"lead_lag\", {\n",
    "                \"time_in\": True,\n",
    "                \"time_out\": False,\n",
    "                \"time_normalisation\": False\n",
    "            }),\n",
    "            (\"basepoint\", {})\n",
    "        ]),\n",
    "        \"subtract_start\": True,\n",
    "        \"preserve_order\": False\n",
    "    }\n",
    "ts, data_size, _, dataloader, _, transformer = get_data(data_type, data_config, device)\n",
    "infinite_dataloader = (elem for it in iter(lambda: dataloader, None) for elem in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generator\n",
    "discriminator_types =  [\n",
    "    \"SigKerMMDDiscriminator\",\n",
    "    \"TruncatedDiscriminator\",\n",
    "    \"CDEDiscriminator\",\n",
    "    \"FDDiscriminator\"\n",
    "]\n",
    "use_averaged      = [False, False, False, False]\n",
    "generators          = []\n",
    "config_paths =[\n",
    "    f\"../checkpoints/forex_metals64/SigKerMMDDiscriminator_seed{seed}/generators/forex_metals_SigKerMMDDiscriminator\",\n",
    "    f\"../checkpoints/forex_metals64/TruncatedDiscriminator_seed{seed}/generators/forex_metals_TruncatedDiscriminator\",\n",
    "    f\"../checkpoints/forex_metals64/CDEDiscriminator_seed{seed}/generators/forex_metals_CDEDiscriminator\",\n",
    "    f\"../checkpoints/forex_metals64/FDDiscriminator_seed{seed}/generators/forex_metals_FDDiscriminator\",\n",
    "]\n",
    "model_paths =[\n",
    "    f\"../checkpoints/forex_metals64/SigKerMMDDiscriminator_seed{seed}/generators/forex_metals_SigKerMMDDiscriminator\",\n",
    "    f\"../checkpoints/forex_metals64/TruncatedDiscriminator_seed{seed}/generators/forex_metals_TruncatedDiscriminator\",\n",
    "    f\"../checkpoints/forex_metals64/CDEDiscriminator_seed{seed}/generators/forex_metals_CDEDiscriminator\",\n",
    "    f\"../checkpoints/forex_metals64/FDDiscriminator_seed{seed}/generators/forex_metals_FDDiscriminator\",\n",
    "]\n",
    "for i, discriminator_type in enumerate(discriminator_types):\n",
    "    print(model_paths[i])\n",
    "    print(config_paths[i])\n",
    "    #try:\n",
    "    generator_state_dict          = torch.load(model_paths[i] + \".pkl\", map_location=device)\n",
    "    averaged_generator_state_dict = torch.load(model_paths[i] + \"_averaged.pkl\", map_location=device)\n",
    "    generator_config              = torch.load(config_paths[0] + \"_config.pkl\", map_location=device)\n",
    "    #except FileNotFoundError as e:\n",
    "    #    print(f\"Model {discriminator_type} needs to be trained according to the parameters above first. See the unconditional_nsde.ipynb notebook.\")\n",
    "\n",
    "    generator = Generator(data_size=data_size, **generator_config).to(device)\n",
    "\n",
    "    if use_averaged[i]:\n",
    "        generator = swa_utils.AveragedModel(generator)\n",
    "        generator.load_state_dict(averaged_generator_state_dict)\n",
    "    else:\n",
    "        generator.load_state_dict(generator_state_dict)\n",
    "        \n",
    "    generators.append(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in generators[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f047827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some sample paths, perform transformations, put onto the cpu \n",
    "real_samples,     = next(iter(dataloader))\n",
    "real_samples      = subtract_initial_point(real_samples).detach().cpu()\n",
    "\n",
    "dims              = int(real_samples.size(-1) - 1)\n",
    "\n",
    "total_generated_samples = torch.zeros([4] + list(real_samples.size()))\n",
    "path_length = data_config[\"path_length\"]\n",
    "batch_size = data_config[\"batch_size\"]\n",
    "for i, generator in enumerate(generators):\n",
    "    total_generated_samples[i] = subtract_initial_point(generator(ts, eval_batch_size)).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plot_samples = 64\n",
    "height = 4\n",
    "\n",
    "real_plot_samples = real_samples[..., 1:]\n",
    "real_plot_samples = real_plot_samples[:num_plot_samples]\n",
    "print(\"signature kernel,\", \"trucated signature kernel,\", \"neural sde as gan,\", \"finite dimensional mathching,\")\n",
    "\n",
    "for k in range(dims):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5), sharex=True, sharey=True)\n",
    "    for generated_samples, ax in zip(total_generated_samples, axes):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_plot_samples = generated_samples.cpu()[..., 1:]\n",
    "\n",
    "        generated_plot_samples = generated_plot_samples[:num_plot_samples]\n",
    "        real_first = True\n",
    "        generated_first = True\n",
    "        for real_sample_ in real_plot_samples[..., k]:\n",
    "            kwargs = {'label': r'$\\mathbb{P}_{X^{\\text{true}}}$'} if real_first else {}\n",
    "            ax.plot(ts.cpu(), real_sample_.cpu(), color='dodgerblue', linewidth=0.5, alpha=0.5, **kwargs)\n",
    "            real_first = False\n",
    "        for generated_sample_ in generated_plot_samples[..., k]:\n",
    "            kwargs = {'label': r'$\\mathbb{P}_{X^{\\theta}}$'} if generated_first else {}\n",
    "            ax.plot(ts.cpu(), generated_sample_.cpu(), color='crimson', linewidth=0.5, alpha=0.5, **kwargs)\n",
    "            generated_first = False\n",
    "        ax.legend(fontsize=18)\n",
    "        ax.set_xlabel(\"$t$\")\n",
    "        ax.set_ylabel(\"$X_t$\")\n",
    "        #make_grid(axis=ax)\n",
    "\n",
    "    _label = forex_pairs[k] if data_type == \"forex\" else \"\"\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\n",
    "    #    get_project_root().as_posix() + f\"/data/images/{data_type}/{_label}paths.png\", \n",
    "    #    dpi=100\n",
    "    #)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9315e25",
   "metadata": {},
   "source": [
    "## 1. Qualitative plot of marginals: $S_t, r_t, r^2_t$\n",
    "\n",
    "We first give a plot of the marginals at specified times. This gives a qualitative indication to model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(gen_vals, real_vals, marginals, figsize=(10, 5), title=\"\"):\n",
    "    \n",
    "    n_marginals = len(marginals)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_marginals, figsize=figsize)\n",
    "    \n",
    "    n_paths, length = gen_vals.size()\n",
    "    length += 1\n",
    "    n_bins = min(int(n_paths/10), 100)\n",
    "    \n",
    "    for ii, (ax, marg) in enumerate(zip(axes, marginals)):\n",
    "        gen_slice = gen_vals[:, ii]\n",
    "        real_slice = real_vals[:, ii]\n",
    "        \n",
    "        ax.hist(\n",
    "            real_slice, bins=n_bins, alpha=0.5, label='Real' if ii == 0 else \"\", \n",
    "            color='dodgerblue', histtype=\"bar\", stacked=True, edgecolor=None, density=True)\n",
    "        ax.hist(\n",
    "            gen_slice, bins=n_bins, alpha=0.5, label='Generated' if ii == 0 else \"\", \n",
    "            color='tomato', histtype=\"bar\", stacked=True, edgecolor=None, density=True)\n",
    "        \n",
    "        if ii == 0:\n",
    "            ax.legend(loc=\"upper left\", fontsize=\"small\")\n",
    "        \n",
    "        ax.set_ylabel('density')\n",
    "        make_grid(axis=ax)\n",
    "        \n",
    "        ax.set_title(f'Marginal distribution at time {int(marg*length)}, ' + title, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce13273",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_marginals = (0.1, 0.3, 0.5, 0.7, 0.9)\n",
    "height = 4\n",
    "figsize = (height*GOLDEN_RATIO*len(pct_marginals), height)\n",
    "marginals = [int(data_config[\"path_length\"]*pcm) for pcm in pct_marginals]\n",
    "\n",
    "for generated_samples in total_generated_samples:\n",
    "    for k in range(dims):\n",
    "        generated_levels  = generated_samples[:, 1:, k+1]\n",
    "        generated_rets    = torch.diff(generated_samples[..., k+1], axis=1)\n",
    "        generated_ret_sqs = torch.pow(generated_rets, 2)\n",
    "\n",
    "        real_levels  = real_samples[:, 1:, k+1]\n",
    "        real_rets    = torch.diff(real_samples[..., k+1], axis=1)\n",
    "        real_ret_sqs = torch.pow(real_rets, 2)\n",
    "        \n",
    "        title = forex_pairs[k] if data_type == \"forex\" else \"\"\n",
    "\n",
    "        plot_histograms(generated_levels, real_levels  , pct_marginals, figsize=figsize, title=title)\n",
    "        plot_histograms(generated_rets, real_rets      , pct_marginals, figsize=figsize, title=title)\n",
    "        plot_histograms(generated_ret_sqs, real_ret_sqs, pct_marginals, figsize=figsize, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f58dc",
   "metadata": {},
   "source": [
    "## 2. Kolmogorov-Smirnov $p$-values\n",
    "\n",
    "We now report the Kolmogorov-Smirnov test statistic (and $p$-values) between the generated paths and real paths at given marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd01387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "marginals = (0.1, 0.3, 0.5, 0.7, 0.9)\n",
    "alpha     = 0.95\n",
    "tol       = 1 - alpha\n",
    "n_runs    = 5000  # TODO: revert back to 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ks_results = generate_ks_results(ts, infinite_dataloader, generators, marginals, n_runs, dims=dims, eval_batch_size=eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbfcc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(dims):\n",
    "    print(f\"Dimension: {k+1}\")\n",
    "    for i, m in enumerate(marginals):\n",
    "        print(f\"Marginal {int(path_length*m)}:\")\n",
    "\n",
    "        for j, disc in enumerate(discriminator_types):\n",
    "            print(j, k, i, total_ks_results.shape)\n",
    "            average_score  = np.mean(total_ks_results[j, :, k, i, 0])\n",
    "            std_score      = np.std(total_ks_results[j, :, k, i, 0])\n",
    "            percent_reject = sum(total_ks_results[j, :, k, i, 1] <= tol)/n_runs\n",
    "\n",
    "            lci, hci = st.norm.interval(confidence=alpha, loc=average_score, scale=std_score)\n",
    "\n",
    "            print(f\"{disc}: Average KS score: {average_score:.4f}, \" \n",
    "                  f\"% reject: {percent_reject*100:.1f}, CI: {lci:.4f}, {hci:.4f}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c001982",
   "metadata": {},
   "source": [
    "## 3. Autocorrelation scores and plots\n",
    "\n",
    "Here, we give a plot of the $n$-lagged autocorrelation (ACF) scores between the generated and real data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18714b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests        = 100\n",
    "n_models = len(discriminator_types)\n",
    "n_lags         = 14\n",
    "acf_lags       = np.arange(n_lags+1)\n",
    "test_acf_means = np.zeros((dims, n_lags+1))\n",
    "test_acf_stds  = np.zeros((dims, n_lags+1))\n",
    "rucis          = np.ones((dims, n_lags+1))\n",
    "rlcis          = np.ones((dims, n_lags+1))\n",
    "\n",
    "gen_acf_means  = np.zeros((n_models, dims, n_lags + 1))\n",
    "gen_acf_stds   = np.zeros((n_models, dims, n_lags + 1))\n",
    "gucis          = np.ones((n_models, dims, n_lags + 1))\n",
    "glcis          = np.ones((n_models, dims, n_lags + 1))\n",
    "\n",
    "for _ in range(n_tests):\n",
    "    acf_real_samples,     = next(iter(dataloader))\n",
    "    acf_real_samples      = subtract_initial_point(acf_real_samples).detach().cpu()\n",
    "\n",
    "\n",
    "    acf_total_generated_samples = torch.zeros([n_models] + list(acf_real_samples.size()))\n",
    "\n",
    "    for i, generator in enumerate(generators):\n",
    "        acf_total_generated_samples[i] = subtract_initial_point(generator(ts, eval_batch_size)).detach().cpu()\n",
    "\n",
    "    for k in range(dims):\n",
    "\n",
    "        test_acfs         = np.array([acf(xi, nlags=n_lags) for xi in acf_real_samples[..., k+1]])\n",
    "        test_acf_means[k] += test_acfs.mean(axis=0)\n",
    "        test_acf_stds[k]  += test_acfs.std(axis=0)\n",
    "\n",
    "        for i, generated_samples in enumerate(acf_total_generated_samples):\n",
    "\n",
    "            gen_acfs            = np.array([acf(xi, nlags=n_lags) for xi in generated_samples[..., k+1]])\n",
    "\n",
    "            gen_acf_means[i, k] += gen_acfs.mean(axis=0)\n",
    "            gen_acf_stds[i, k]  += gen_acfs.std(axis=0)\n",
    "\n",
    "test_acf_means /= n_tests\n",
    "test_acf_stds /= n_tests\n",
    "\n",
    "gen_acf_means/=n_tests\n",
    "gen_acf_stds/=n_tests\n",
    "\n",
    "for k in range(dims):\n",
    "    print(f\"Dim {k+1}:\")\n",
    "    for l in acf_lags[1:]:\n",
    "        real_mean   = test_acf_means[k, l]\n",
    "        real_std    = test_acf_stds[k, l]\n",
    "        rlci, ruci  = st.norm.interval(confidence=alpha, loc=real_mean, scale=real_std)\n",
    "        rucis[k, l] = ruci\n",
    "        rlcis[k, l] = rlci\n",
    "\n",
    "        if l < 6:\n",
    "            print(f\"\\nLag {l}\")\n",
    "            print(f\"Real mean: {real_mean:.4f}, confidence interval: {rlci:.4f}, {ruci:.4f}, val: {real_mean-rlci:.4f}\")\n",
    "\n",
    "        for j, disc in enumerate(discriminator_types):\n",
    "\n",
    "            gen_mean    = gen_acf_means[j, k, l]\n",
    "            gen_std     = gen_acf_stds[j, k, l]\n",
    "            glci, guci  = st.norm.interval(confidence=alpha, loc=gen_mean, scale=gen_std)\n",
    "            gucis[j, k, l] = guci\n",
    "            glcis[j, k, l] = glci\n",
    "\n",
    "            if l < 6:\n",
    "                print(f\"{disc} mean: {gen_mean:.4f}, confidence interval: {glci:.4f}, {guci:.4f}, val: {gen_mean-glci:.4f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ded25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(dims):\n",
    "    print(f\"Dim {k+1}\")\n",
    "    for l in acf_lags[1:6]:\n",
    "        min_ind = np.argmin([np.sqrt(np.power(test_acf_means[k, l] - gen_acf_means[i, k, l], 2)) for i in range(n_models)])\n",
    "        print(f\"Lag {l}: {discriminator_types[min_ind]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4698d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 3\n",
    "\n",
    "for k in range(dims):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(15, 5))\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "\n",
    "        ax.plot(test_acf_means[k], color=\"dodgerblue\", alpha=0.25, linestyle=\"dashed\", label=r'$\\mathbb{P}_{X^{\\text{true}}}$')\n",
    "        ax.fill_between(acf_lags, rlcis[k], rucis[k], color=\"dodgerblue\", alpha=0.25)\n",
    "\n",
    "        ax.plot(gen_acf_means[i, k] , color=\"tomato\", alpha=0.25, linestyle=\"dashed\", label=r'$\\mathbb{P}_{X^{\\theta}}$')\n",
    "        ax.fill_between(acf_lags, glcis[i, k], gucis[i, k], color=\"tomato\", alpha=0.25)\n",
    "\n",
    "        ax.scatter(np.arange(n_lags+1), test_acf_means[k], color=\"dodgerblue\", alpha=0.75, s=6)\n",
    "        ax.scatter(np.arange(n_lags+1), gen_acf_means[i, k], color=\"tomato\", alpha=0.75, s=6)\n",
    "\n",
    "        #make_grid(axis=ax)\n",
    "        ax.legend(fontsize=18, loc=3);\n",
    "        ax.set_xlabel(r\"$l$\", fontsize=16)\n",
    "        ax.set_ylabel(r\"$\\mathrm{ACF}_l$\", fontsize=16)\n",
    "\n",
    "        title = forex_pairs[k] if data_type == \"forex\" else \"\"\n",
    "\n",
    "        #ax.set_title(f\"ACF plot, trained with: {disc}\" + title, fontsize=\"small\")\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(\n",
    "        #    get_project_root().as_posix() + f\"/data/images/{data_type}/{title}acf.png\", \n",
    "        #    dpi=100\n",
    "        #)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95884d14",
   "metadata": {},
   "source": [
    "## 4. Cross-covariance between $r_t, r^2_t$\n",
    "\n",
    "Finally we plot the cross-covariance matrix between the generated and real $(r_t, r^2_t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some sample paths, perform transformations, put onto the cpu \n",
    "real_samples,     = next(iter(dataloader))\n",
    "real_samples      = subtract_initial_point(real_samples).detach().cpu()\n",
    "\n",
    "dims              = int(real_samples.size(-1) - 1)\n",
    "\n",
    "total_generated_samples = torch.zeros([n_models] + list(real_samples.size()))\n",
    "\n",
    "for i, generator in enumerate(generators):\n",
    "    total_generated_samples[i] = subtract_initial_point(generator(ts, eval_batch_size)).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = (0, 1, 2, 3, 4, 5, 6)\n",
    "columns = [\"$r_t$\"] + [f\"$r^2_{l}$\"for l in lags[:-1]]\n",
    "xcolumns = columns[:-1] + [\"\"]\n",
    "ycolumns = [\"\"] + columns[1:]\n",
    "\n",
    "for k in range(dims):\n",
    "    print(f\"dim={k}\")\n",
    "    real_ccov_paths = torch.zeros((batch_size, path_length-1, 2))\n",
    "\n",
    "    real_ret_paths          = (real_samples[..., 1:, k+1]+1)/(real_samples[..., :-1, k+1]+1) - 1\n",
    "    real_ret_sq_paths       = real_ret_paths**2\n",
    "    real_ccov_paths[..., 0] = real_ret_paths\n",
    "    real_ccov_paths[..., 1] = real_ret_sq_paths\n",
    "    real_ccor_matrix        = get_ccor_matrix(real_ccov_paths, lags=lags)\n",
    "\n",
    "    gen_ccov_paths = torch.zeros((n_models, batch_size, path_length-1, 2))\n",
    "\n",
    "    for i, generated_samples in enumerate(total_generated_samples):\n",
    "\n",
    "        gen_ret_paths     = (generated_samples[..., 1:, k+1]+1)/(generated_samples[..., :-1, k+1]+1) - 1\n",
    "        gen_ret_sq_paths  = gen_ret_paths**2\n",
    "\n",
    "        gen_ccov_paths[i, ..., 0] = gen_ret_paths\n",
    "        gen_ccov_paths[i, ..., 1] = gen_ret_sq_paths\n",
    "\n",
    "    gen_ccor_matrices = np.zeros([n_models] + list(real_ccor_matrix.shape))\n",
    "\n",
    "    for i, g_ccov_paths in enumerate(gen_ccov_paths):\n",
    "        gen_ccor_matrices[i] = get_ccor_matrix(g_ccov_paths, lags=lags)\n",
    "\n",
    "    fig, ax   = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    \n",
    "\n",
    "    plot_matrix = pd.DataFrame(np.round(real_ccor_matrix, 3), columns=columns)\n",
    "\n",
    "    mask = np.triu(np.ones_like(plot_matrix, dtype=bool))\n",
    "    cmap = sns.blend_palette([\"dodgerblue\", \".9\", \"tomato\"], as_cmap=True)\n",
    "\n",
    "    sns.heatmap(plot_matrix, mask=mask, annot=True, fmt='g', cmap=cmap, center=0, \n",
    "                ax=ax, square=True, linewidths=.5, vmin=0, vmax=0.4, xticklabels=xcolumns, yticklabels=ycolumns,\n",
    "                annot_kws={\"size\": 7}, cbar_kws={\"shrink\": .5})\n",
    "    #ax.set_title(f\"Cross-correlation heatmap, {data_type}, data measure\" + title,fontsize=10)\n",
    "    \n",
    "    extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    _label = forex_pairs[k] if data_type == \"forex\" else \"\"\n",
    "    #plt.savefig(\n",
    "    #    get_project_root().as_posix() + f\"/data/images/{data_type}/datameasure{_label}matrix.png\", \n",
    "    #    dpi=100, bbox_inches=extent\n",
    "    #)\n",
    "\n",
    "\n",
    "    for i, gen_ccor_matrix in enumerate(gen_ccor_matrices):\n",
    "        \n",
    "        fig, ax   = plt.subplots(1, 1, figsize=(4, 4))\n",
    "        plot_matrix = pd.DataFrame(np.round(gen_ccor_matrix, 3), columns=columns)\n",
    "\n",
    "        sns.heatmap(plot_matrix, mask=mask, annot=True, fmt='g', cmap=cmap, center=0, \n",
    "                    ax=ax, square=True, linewidths=.5, vmin=0, vmax=0.4, xticklabels=xcolumns, yticklabels=ycolumns,\n",
    "                    annot_kws={\"size\": 7}, cbar_kws={\"shrink\": .5})\n",
    "        ax.tick_params(axis='both', which='both', length=0)\n",
    "        #ax.set_title(f\"Cross-correlation heatmap, {data_type}, {discriminator_types[i]}\" + title,fontsize=10)\n",
    "        extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        #plt.savefig(\n",
    "        #    get_project_root().as_posix() + f\"/data/images/{data_type}/{discriminator_types[i]}{_label}matrix.png\", \n",
    "        #    dpi=100, bbox_inches=extent\n",
    "        #)\n",
    "\n",
    "    for i, gen_ccor_matrix in enumerate(gen_ccor_matrices):\n",
    "\n",
    "        mse = torch.sum(torch.pow(real_ccor_matrix - gen_ccor_matrix, 2)).item()\n",
    "\n",
    "        print(f\"{discriminator_types[i]} MSE: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 8\n",
    "batch_size, length, dim = real_samples.size()\n",
    "\n",
    "n_bins = int(n_repeats*eval_batch_size/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba27ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_real_samples  = torch.empty((0, length, dim))\n",
    "total_gen_samples = torch.empty((n_models, int(n_repeats*eval_batch_size), length, dim))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_repeats):\n",
    "        real_samples,     = next(iter(dataloader))\n",
    "        real_samples      = subtract_initial_point(real_samples).detach().cpu()\n",
    "        \n",
    "        tot_real_samples = torch.cat([tot_real_samples, real_samples], dim=0)\n",
    "\n",
    "    for i, generator in enumerate(generators):\n",
    "        tot_gen_samples = torch.empty((0, length, dim))\n",
    "        for _ in range(n_repeats):\n",
    "            gen_samples        = subtract_initial_point(generator(ts, eval_batch_size)).cpu()     \n",
    "            tot_gen_samples = torch.cat([tot_gen_samples, gen_samples], dim=0)\n",
    "            \n",
    "        total_gen_samples[i] = tot_gen_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b693dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_discriminator_types = [r\"$\\phi_{\\text{sig}}$\", r\"$\\phi^N_{\\text{sig}}$\", \"SDE-GAN\"]\n",
    "\n",
    "if data_type == \"forex\":\n",
    "    # Provide correlation of paths as well\n",
    "    real_corrcoefs = np.array([\n",
    "        np.corrcoef(r1, r2)[0,1] for r1, r2 in zip(tot_real_samples[:, 1:, 1], tot_real_samples[:, 1:, 2])\n",
    "    ])\n",
    "    \n",
    "    fig, ax = plt.subplots(1, n_models, figsize=(15,5))\n",
    "    \n",
    "    for k, (axi, generated_samples) in enumerate(zip(ax, total_gen_samples)):\n",
    "        \n",
    "        \n",
    "        gen_corrcoefs = np.array([\n",
    "            np.corrcoef(r1, r2)[0,1] for r1, r2 in zip(generated_samples[:, 1:, 1], generated_samples[:, 1:, 2])\n",
    "        ])\n",
    "        \n",
    "        axi.hist(\n",
    "            real_corrcoefs, bins=n_bins, color=\"dodgerblue\", alpha=0.5, density=True, label=r\"$\\mathbb{P}_{X^{\\text{true}}}$\"\n",
    "        )\n",
    "        \n",
    "        axi.hist(\n",
    "            gen_corrcoefs, bins=n_bins, color=\"tomato\", alpha=0.5, density=True, label=r\"$\\mathbb{P}_{X^\\theta}$\"\n",
    "        )\n",
    "        \n",
    "        #make_grid(axis=axi)\n",
    "        \n",
    "        #ax.set_title(f\"Correlation coefficient distribution, {_discriminator_types[k]}\", fontsize=\"large\")\n",
    "        axi.set_xlabel(r\"$\\rho$\", fontsize=16)\n",
    "        axi.legend(fontsize=18)\n",
    "#plt.savefig('corrcoefs.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1346e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names =  [\n",
    "    \"Signature Kernel\",\n",
    "    \"Truncated Signature\",\n",
    "    \"SDE-GAN\",\n",
    "    \"FDM\"\n",
    "]\n",
    "\n",
    "N,T,_ = total_generated_samples[0].shape\n",
    "timestamps = [int(0.1 * T), int(0.3 * T), int(0.5 * T), int(0.7 * T), int(0.9 * T)]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(\n",
    "    len(total_generated_samples), len(timestamps), figsize=(15, 10), \n",
    "    sharex=True, sharey=True, dpi=300)\n",
    "\n",
    "for i, tensor in enumerate(total_generated_samples):\n",
    "    for j, t in enumerate(timestamps):\n",
    "        ax = axes[i, j]\n",
    "        ax.scatter(tot_real_samples[:, t, 1].numpy(), tot_real_samples[:, t, 2].numpy(), alpha=0.01, color='dodgerblue')\n",
    "#         ax.scatter(tot_real_samples[:128, t, 1].numpy(), tot_real_samples[:128, t, 2].numpy(), alpha=0.1, color='r')\n",
    "        ax.scatter(tensor[:, t, 1].numpy(), tensor[:, t, 2].numpy(), alpha=0.05, color='tomato')\n",
    "#         ax.set_title(f'Sample {i+1}, Time {t}')\n",
    "#         ax.set_title(f'Sample {i+1}, t={t}')\n",
    "#         ax.set_title(f'Sample {i+1}, t={t}')\n",
    "        if i == 0:\n",
    "            ax.set_title(f't={t}', fontsize=18)\n",
    "        if j == len(timestamps) - 1:\n",
    "            ax.set_ylabel(f'{model_names[i]}', fontsize=16)\n",
    "            ax.yaxis.set_label_position(\"right\")\n",
    "#         ax.set_xlabel('EURUSD', fontsize=10)\n",
    "#         ax.set_ylabel('USDJPY', fontsize=10)\n",
    "fig.supxlabel('Silver', fontsize=18)\n",
    "fig.supylabel('Gold', fontsize=18)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(f'forex64_sliver_gold_seed{seed}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cdc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
